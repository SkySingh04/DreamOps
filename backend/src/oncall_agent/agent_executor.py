"""Agent executor that handles command execution based on AI mode."""

import logging
from collections.abc import Callable
from datetime import datetime
from typing import Any

from src.oncall_agent.api.log_streaming import log_stream_manager
from src.oncall_agent.api.schemas import AIMode
from src.oncall_agent.mcp_integrations.kubernetes_manusa_mcp import (
    KubernetesManusaMCPIntegration,
)
from src.oncall_agent.strategies.kubernetes_resolver import ResolutionAction


class AgentExecutor:
    """Handles execution of remediation actions based on AI mode and risk assessment."""

    def __init__(self, k8s_integration: KubernetesManusaMCPIntegration | None = None):
        """Initialize the agent executor."""
        self.logger = logging.getLogger(__name__)
        self.k8s_integration = k8s_integration
        self.execution_history = []
        self.circuit_breaker = CircuitBreaker()

    async def execute_mcp_action(self, action_type: str, params: dict[str, Any]) -> dict[str, Any]:
        """Execute action via MCP server integration."""
        self.logger.info(f"Executing MCP action: {action_type}")

        # Stream log for action
        await log_stream_manager.log_info(
            f"ðŸ”¨ Running MCP action: {action_type}",
            action_type="mcp_action",
            metadata={"action": action_type, "params": params}
        )

        # Use MCP integration if available
        if self.k8s_integration:
            return await self.k8s_integration.execute_action(
                action_type,
                params
            )
        else:
            return {
                "success": False,
                "error": "No Kubernetes MCP integration available. Please ensure @modelcontextprotocol/server-kubernetes is installed.",
                "action": action_type
            }

    async def execute_remediation_plan(
        self,
        actions: list[ResolutionAction],
        incident_id: str,
        ai_mode: AIMode,
        confidence_threshold: float = 0.8,
        approval_callback: Callable | None = None
    ) -> dict[str, Any]:
        """Execute a remediation plan based on AI mode and confidence.
        
        Args:
            actions: List of resolution actions to execute
            incident_id: ID of the incident being resolved
            ai_mode: Current AI operation mode (YOLO, APPROVAL, PLAN)
            confidence_threshold: Minimum confidence required for auto-execution
            approval_callback: Async function to get approval (for APPROVAL mode)
            
        Returns:
            Execution results with status and details
        """
        results = {
            "incident_id": incident_id,
            "mode": ai_mode.value,
            "actions_proposed": len(actions),
            "actions_executed": 0,
            "actions_successful": 0,
            "actions_failed": 0,
            "execution_details": []
        }

        # Log remediation plan start
        await log_stream_manager.log_info(
            f"ðŸš€ Starting remediation plan with {len(actions)} actions",
            incident_id=incident_id,
            stage="remediation_start",
            metadata={
                "ai_mode": ai_mode.value,
                "total_actions": len(actions),
                "action_types": [a.action_type for a in actions]
            }
        )

        # Check circuit breaker - but reset it in YOLO mode since all errors are fixable
        if self.circuit_breaker.is_open():
            if ai_mode == AIMode.YOLO:
                self.logger.warning("Circuit breaker is open but resetting for YOLO mode")
                self.circuit_breaker.reset()
            else:
                self.logger.warning("Circuit breaker is open - too many failures")
                results["error"] = "Circuit breaker open - automatic execution disabled"
                return results

        for action in actions:
            # Prepare execution context
            execution_context = {
                "action": {
                    "action_type": action.action_type,
                    "description": action.description,
                    "params": action.params,
                    "confidence": action.confidence,
                    "risk_level": action.risk_level,
                    "estimated_time": action.estimated_time,
                    "rollback_possible": action.rollback_possible
                },
                "incident_id": incident_id,
                "timestamp": datetime.utcnow().isoformat(),
                "mode": ai_mode.value
            }

            try:
                # Determine if we should execute
                should_execute, reason = await self._should_execute_action(
                    action, ai_mode, confidence_threshold, approval_callback
                )

                if should_execute:
                    # Execute the action
                    exec_result = await self._execute_single_action(action, ai_mode)
                    execution_context["executed"] = True
                    execution_context["result"] = exec_result

                    if exec_result["success"]:
                        results["actions_successful"] += 1
                        self.circuit_breaker.record_success()

                        await log_stream_manager.log_success(
                            f"âœ… Action {results['actions_executed'] + 1}/{len(actions)} completed successfully",
                            incident_id=incident_id,
                            progress=(results["actions_executed"] + 1) / len(actions),
                            metadata={"action_type": action.action_type}
                        )

                        # Verify the action worked
                        if action.action_type in ["restart_pod", "scale_deployment", "rollback_deployment"]:
                            verify_result = await self._verify_action(action)
                            execution_context["verification"] = verify_result
                    else:
                        results["actions_failed"] += 1
                        self.circuit_breaker.record_failure()

                        await log_stream_manager.log_error(
                            f"âŒ Action {results['actions_executed'] + 1}/{len(actions)} failed",
                            incident_id=incident_id,
                            metadata={
                                "action_type": action.action_type,
                                "error": exec_result.get("error")
                            }
                        )

                    results["actions_executed"] += 1
                else:
                    execution_context["executed"] = False
                    execution_context["reason"] = reason

                    await log_stream_manager.log_warning(
                        f"â­ï¸ Skipped action: {action.action_type} - {reason}",
                        incident_id=incident_id,
                        metadata={"action_type": action.action_type, "reason": reason}
                    )

            except Exception as e:
                self.logger.error(f"Error executing action {action.action_type}: {e}")
                execution_context["error"] = str(e)
                results["actions_failed"] += 1
                self.circuit_breaker.record_failure()

            results["execution_details"].append(execution_context)
            self.execution_history.append(execution_context)

            # Stop if we've had too many failures
            if results["actions_failed"] >= 3:
                self.logger.warning("Too many failures - stopping execution")
                await log_stream_manager.log_error(
                    "ðŸ›‘ Stopping execution due to too many failures",
                    incident_id=incident_id,
                    metadata={"failed_count": results["actions_failed"]}
                )
                break

        # Log remediation completion
        await log_stream_manager.log_info(
            f"ðŸŽ¯ Remediation plan completed: {results['actions_successful']}/{results['actions_executed']} actions successful",
            incident_id=incident_id,
            stage="remediation_complete",
            progress=1.0,
            metadata={
                "successful": results["actions_successful"],
                "failed": results["actions_failed"],
                "total_executed": results["actions_executed"]
            }
        )

        return results

    async def _should_execute_action(
        self,
        action: ResolutionAction,
        ai_mode: AIMode,
        confidence_threshold: float,
        approval_callback: Callable | None
    ) -> tuple[bool, str]:
        """Determine if an action should be executed based on mode and confidence."""

        # Check confidence threshold
        if ai_mode != AIMode.YOLO and action.confidence < confidence_threshold:
            return False, f"Confidence {action.confidence} below threshold {confidence_threshold}"
        # In YOLO mode, we execute regardless of confidence since all errors are fixable

        # Check risk level
        if action.risk_level == "high" and ai_mode != AIMode.YOLO:
            return False, "High risk action requires YOLO mode or manual approval"

        # Mode-specific logic
        if ai_mode == AIMode.YOLO:
            # YOLO mode - ALWAYS execute because all simulated errors are fixable!
            # Trust the remediation since errors are from fuck_kubernetes.sh
            self.logger.info(f"ðŸš€ YOLO: Executing {action.action_type} (confidence: {action.confidence}, risk: {action.risk_level})")
            return True, "YOLO mode - auto-executing (all simulated errors are fixable)"

        elif ai_mode == AIMode.APPROVAL:
            # Approval mode - need explicit approval
            if approval_callback:
                approved = await approval_callback(action)
                if approved:
                    return True, "User approved action"
                else:
                    return False, "User rejected action"
            else:
                return False, "Approval required but no callback provided"

        elif ai_mode == AIMode.PLAN:
            # Plan mode - only show what would be done
            return False, "Plan mode - execution disabled"

        return False, f"Unknown mode: {ai_mode}"

    async def _execute_single_action(self, action: ResolutionAction, ai_mode: AIMode) -> dict[str, Any]:
        """Execute a single remediation action."""
        self.logger.info(f"Executing {action.action_type} action (risk: {action.risk_level})")

        # Stream log for action execution start
        await log_stream_manager.log_info(
            f"ðŸ”§ Executing action: {action.action_type}",
            action_type=action.action_type,
            metadata={
                "risk_level": action.risk_level,
                "confidence": action.confidence,
                "description": action.description
            }
        )

        # Map action types to execution methods
        action_mapping = {
            "restart_pod": self._execute_restart_pod,
            "scale_deployment": self._execute_scale_deployment,
            "rollback_deployment": self._execute_rollback_deployment,
            "increase_memory_limit": self._execute_increase_memory,
            "check_configmaps_secrets": self._execute_check_configs,
            "check_dependencies": self._execute_check_dependencies,
            # New action types for generic pod errors and OOM
            "identify_error_pods": self._execute_identify_error_pods,
            "restart_error_pods": self._execute_restart_error_pods,
            "check_resource_constraints": self._execute_check_resource_constraints,
            "identify_oom_pods": self._execute_identify_oom_pods,
            "increase_memory_limits": self._execute_increase_memory_limits,
            # Deterministic fix actions
            "update_image": self._execute_update_image,
            "delete_pods_by_label": self._execute_delete_pods_by_label,
            "patch_memory_limit": self._execute_patch_memory_limit,
        }

        executor = action_mapping.get(action.action_type)
        if not executor:
            return {"success": False, "error": f"No executor for action type: {action.action_type}"}

        # Execute with appropriate auto-approval based on mode
        auto_approve = ai_mode == AIMode.YOLO

        try:
            result = await executor(action, auto_approve)

            # Stream log for action result
            if result.get("success"):
                await log_stream_manager.log_success(
                    f"âœ… Action completed: {action.action_type}",
                    action_type=action.action_type,
                    metadata={"output": result.get("output", "")[:500]}  # Truncate long outputs
                )
            else:
                await log_stream_manager.log_error(
                    f"âŒ Action failed: {action.action_type}",
                    action_type=action.action_type,
                    metadata={"error": result.get("error", "Unknown error")}
                )

            return result
        except Exception as e:
            await log_stream_manager.log_error(
                f"âŒ Exception during action: {action.action_type}",
                action_type=action.action_type,
                metadata={"error": str(e)}
            )
            raise

    async def _execute_restart_pod(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Execute pod restart."""
        return await self.execute_mcp_action("restart_pod", action.params)

    async def _execute_scale_deployment(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Execute deployment scaling."""
        return await self.execute_mcp_action("scale_deployment", action.params)

    async def _execute_rollback_deployment(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Execute deployment rollback."""
        return await self.execute_mcp_action("rollback_deployment", action.params)

    async def _execute_increase_memory(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Execute memory limit increase."""
        params = action.params
        # This would need to patch the deployment/pod spec
        deployment_name = params.get("deployment_name")
        if not deployment_name:
            return {"success": False, "error": "No deployment name provided"}

        # Calculate new memory limit
        increase_pct = params.get("memory_increase", "50%")

        # Prepare patch for MCP
        patch_params = {
            "kind": "deployment",
            "name": deployment_name,
            "namespace": params["namespace"],
            "patch": [{"op": "replace", "path": "/spec/template/spec/containers/0/resources/limits/memory", "value": "512Mi"}],
            "patch_type": "json"
        }

        return await self.execute_mcp_action("patch_resource", patch_params)

    async def _execute_check_configs(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Check ConfigMaps and Secrets."""
        params = action.params
        namespace = params["namespace"]

        # Since configmaps and secrets aren't direct fetch_context types,
        # we'll use describe_resource for specific ones if provided,
        # or return a message indicating manual check is needed

        results = {
            "success": True,
            "message": "ConfigMaps and Secrets check requested",
            "namespace": namespace
        }

        # If specific configmap or secret names are provided, describe them
        if "configmap_name" in params:
            cm_result = await self.execute_mcp_action(
                "describe_resource",
                {"kind": "configmap", "name": params["configmap_name"], "namespace": namespace}
            )
            results["configmap"] = cm_result.get("description", "")
            results["success"] = results["success"] and cm_result.get("success", False)

        if "secret_name" in params:
            secret_result = await self.execute_mcp_action(
                "describe_resource",
                {"kind": "secret", "name": params["secret_name"], "namespace": namespace}
            )
            results["secret"] = secret_result.get("description", "")
            results["success"] = results["success"] and secret_result.get("success", False)

        return results

    async def _execute_check_dependencies(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Check service dependencies."""
        params = action.params
        namespace = params["namespace"]

        # Get services in namespace
        svc_result = await self.execute_mcp_action(
            "fetch_context",
            {"type": "services", "namespace": namespace}
        )

        # For endpoints, we'll check specific services if provided
        results = {
            "success": svc_result.get("success", False),
            "services": svc_result.get("services", svc_result),
            "namespace": namespace
        }

        # If specific service names are provided, describe them for endpoint info
        if "service_names" in params:
            endpoint_info = {}
            for service_name in params["service_names"]:
                ep_result = await self.execute_mcp_action(
                    "describe_resource",
                    {"kind": "endpoints", "name": service_name, "namespace": namespace}
                )
                endpoint_info[service_name] = ep_result.get("description", "No endpoint info")
            results["endpoints"] = endpoint_info

        return results

    async def _verify_action(self, action: ResolutionAction) -> dict[str, Any]:
        """Verify that an action was successful."""
        # Simple verification by checking resource status
        params = action.params

        if action.action_type == "restart_pod":
            # Check if pod is running again
            result = await self.execute_mcp_action(
                "describe_resource",
                {"kind": "pod", "name": params["pod_name"], "namespace": params["namespace"]}
            )
            if result["success"]:
                try:
                    # Parse the description to find status
                    description = result.get("description", "")
                    if "Status:" in description:
                        status_line = [line for line in description.split("\n") if "Status:" in line]
                        if status_line:
                            status = status_line[0].split(":")[1].strip()
                            return {"verified": status == "Running", "status": status}
                    return {"verified": False, "reason": "Could not parse pod status"}
                except:
                    return {"verified": False, "reason": "Failed to parse pod status"}
            return {"verified": False, "reason": result.get("error")}

        elif action.action_type == "scale_deployment":
            # Check if replicas match
            result = await self.execute_mcp_action(
                "describe_resource",
                {"kind": "deployment", "name": params["deployment_name"], "namespace": params["namespace"]}
            )
            if result["success"]:
                try:
                    # Parse the description to find replicas
                    description = result.get("description", "")
                    if "Replicas:" in description:
                        replicas_line = [line for line in description.split("\n") if "Replicas:" in line]
                        if replicas_line:
                            # Extract replica numbers from line like "Replicas: 3 desired | 3 updated | 3 total"
                            parts = replicas_line[0].split()
                            desired = int(parts[1]) if len(parts) > 1 else 0
                            return {"verified": desired == params["replicas"],
                                   "desired": desired, "ready": desired}
                    return {"verified": False, "reason": "Could not parse deployment status"}
                except:
                    return {"verified": False, "reason": "Failed to parse deployment status"}
            return {"verified": False, "reason": result.get("error")}

        return {"verified": True, "reason": "Verification not implemented for this action type"}

    def get_execution_history(self) -> list[dict[str, Any]]:
        """Get the history of executed actions."""
        return self.execution_history

    async def _execute_identify_error_pods(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Identify pods with errors."""
        params = action.params
        namespace = params.get("namespace", "default")

        await log_stream_manager.log_info(
            f"ðŸ” Scanning for error pods in namespace: {namespace}",
            action_type="identify_error_pods",
            metadata={"namespace": namespace}
        )

        # Get all pods and filter for error states
        if params.get("check_all_namespaces"):
            # For all namespaces, we need to get pods differently
            # MCP might not support "all" namespace in fetch_context
            result = await self.execute_mcp_action(
                "fetch_context",
                {"type": "pods", "namespace": "default"}  # Start with default
            )
            # Note: Full all-namespace support would require listing namespaces first
            # and then iterating through them
        else:
            result = await self.execute_mcp_action(
                "fetch_context",
                {"type": "pods", "namespace": namespace}
            )

        if result.get("success"):
            # Handle the result from fetch_context which returns structured data
            pods_data = result.get("pods", result)
            error_pods = []

            # If we got a list of pods or items
            if isinstance(pods_data, dict) and "items" in pods_data:
                for pod in pods_data["items"]:
                    status = pod.get("status", {}).get("phase", "")
                    if status in ["Failed", "Pending"] or any(cs.get("state", {}).get("waiting", {}).get("reason", "") in ["CrashLoopBackOff", "ImagePullBackOff", "ErrImagePull"] for cs in pod.get("status", {}).get("containerStatuses", [])):
                        pod_name = pod.get("metadata", {}).get("name", "unknown")
                        pod_namespace = pod.get("metadata", {}).get("namespace", "unknown")
                        error_pods.append(f"{pod_namespace} {pod_name} {status}")
            elif isinstance(pods_data, str):
                # Fallback to string parsing if we got plain text
                for line in pods_data.split("\n")[1:]:  # Skip header
                    if any(state in line for state in ["Error", "CrashLoopBackOff", "ImagePullBackOff", "Pending"]):
                        error_pods.append(line)

            result["error_pods"] = error_pods
            result["error_count"] = len(error_pods)
            self.logger.info(f"Found {len(error_pods)} pods with errors")

            await log_stream_manager.log_info(
                f"ðŸ“Š Found {len(error_pods)} pods with errors",
                action_type="identify_error_pods",
                metadata={"error_count": len(error_pods), "pods": error_pods[:5]}  # Show first 5
            )

        return result

    async def _execute_restart_error_pods(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Restart pods that are in error state."""
        params = action.params
        namespace = params.get("namespace", "default")
        states = params.get("states", ["Error", "CrashLoopBackOff", "ImagePullBackOff"])

        await log_stream_manager.log_info(
            f"â™»ï¸ Preparing to restart error pods in namespace: {namespace}",
            action_type="restart_error_pods",
            metadata={"namespace": namespace, "target_states": states}
        )

        # First get error pods
        identify_result = await self._execute_identify_error_pods(
            ResolutionAction(
                action_type="identify_error_pods",
                description="",
                params=params,
                confidence=1.0,
                risk_level="low",
                estimated_time="10s",
                rollback_possible=False
            ),
            auto_approve=True
        )

        if not identify_result.get("success"):
            return identify_result

        error_pods = identify_result.get("error_pods", [])
        results = []

        for pod_line in error_pods:
            parts = pod_line.split()
            if len(parts) >= 2:
                pod_namespace = namespace
                pod_name = parts[0]

                # If all namespaces, extract namespace from output
                if params.get("check_all_namespaces") and len(parts) >= 2:
                    pod_namespace = parts[0]
                    pod_name = parts[1]

                # Delete the pod to force restart
                result = await self.execute_mcp_action(
                    "delete_resource",
                    {"kind": "pod", "name": pod_name, "namespace": pod_namespace}
                )
                results.append({
                    "pod": pod_name,
                    "namespace": pod_namespace,
                    "result": result
                })

        return {
            "success": all(r["result"].get("success") for r in results),
            "restarted_pods": len(results),
            "details": results
        }

    async def _execute_check_resource_constraints(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Check if pods are failing due to resource constraints."""
        params = action.params
        namespace = params.get("namespace", "default")

        # Get resource usage via MCP metrics
        result = await self.execute_mcp_action(
            "fetch_context",
            {"type": "metrics", "namespace": namespace}
        )

        return result

    async def _execute_identify_oom_pods(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Identify pods that were OOM killed."""
        params = action.params
        namespace = params.get("namespace", "default")
        timeframe = params.get("timeframe", "1h")

        # Get events looking for OOM kills
        result = await self.execute_mcp_action(
            "fetch_context",
            {"type": "events", "namespace": namespace}
        )

        if result.get("success"):
            # Parse events from fetch_context
            events_data = result.get("events", result)
            oom_deployments = set()

            if isinstance(events_data, dict) and "items" in events_data:
                for event in events_data.get("items", []):
                    reason = event.get("reason", "")
                    if reason == "OOMKilling":
                        # Extract deployment from involved object
                        involved = event.get("involvedObject", {})
                        if involved.get("kind") == "Pod":
                            pod_name = involved.get("name", "")
                            if pod_name and "-" in pod_name:
                                # Extract deployment name from pod name
                                deployment = "-".join(pod_name.split("-")[:-2])
                                if deployment:
                                    oom_deployments.add(deployment)
            elif isinstance(events_data, str) and "OOMKilling" in events_data:
                # Fallback to string parsing
                for line in events_data.split("\n")[1:]:  # Skip header
                    if "OOMKilling" in line:
                        # Extract deployment name from pod name
                        parts = line.split()
                        for part in parts:
                            if "-" in part and not part.startswith("-"):
                                # Likely a pod name, extract deployment
                                deployment = "-".join(part.split("-")[:-2])
                                if deployment:
                                    oom_deployments.add(deployment)

            result["oom_deployments"] = list(oom_deployments)
            result["oom_count"] = len(oom_deployments)

        return result

    async def _execute_increase_memory_limits(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Increase memory limits for deployments with OOM killed pods."""
        params = action.params
        namespace = params.get("namespace", "default")
        increase_percentage = params.get("increase_percentage", 50)

        # First identify OOM deployments
        if params.get("target_deployments") == "auto-detect":
            identify_result = await self._execute_identify_oom_pods(
                ResolutionAction(
                    action_type="identify_oom_pods",
                    description="",
                    params={"namespace": namespace},
                    confidence=1.0,
                    risk_level="low",
                    estimated_time="10s",
                    rollback_possible=False
                ),
                auto_approve=True
            )

            if not identify_result.get("success"):
                return identify_result

            deployments = identify_result.get("oom_deployments", [])
        else:
            deployments = params.get("target_deployments", [])

        results = []
        for deployment in deployments:
            # Patch deployment to increase memory

            result = await self.execute_mcp_action(
                "patch_resource",
                {
                    "kind": "deployment",
                    "name": deployment,
                    "namespace": namespace,
                    "patch": [{"op": "replace", "path": "/spec/template/spec/containers/0/resources/limits/memory", "value": "1Gi"}],
                    "patch_type": "json"
                }
            )
            results.append({
                "deployment": deployment,
                "result": result
            })

        return {
            "success": all(r["result"].get("success") for r in results),
            "patched_deployments": len(results),
            "details": results
        }

    async def _execute_update_image(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Update container image in a deployment."""
        params = action.params
        deployment = params["deployment_name"]
        namespace = params["namespace"]
        container = params["container_name"]
        new_image = params["new_image"]

        return await self.execute_mcp_action(
            "set_image",
            {
                "kind": "deployment",
                "name": deployment,
                "namespace": namespace,
                "container": container,
                "image": new_image
            }
        )

    async def _execute_delete_pods_by_label(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Delete pods by label selector."""
        params = action.params
        namespace = params["namespace"]
        selector = params["label_selector"]

        return await self.execute_mcp_action(
            "delete_resource",
            {
                "kind": "pod",
                "namespace": namespace,
                "label_selector": selector
            }
        )

    async def _execute_patch_memory_limit(self, action: ResolutionAction, auto_approve: bool) -> dict[str, Any]:
        """Patch memory limit for a deployment."""
        params = action.params
        deployment = params["deployment_name"]
        namespace = params["namespace"]
        memory_limit = params["memory_limit"]

        return await self.execute_mcp_action(
            "patch_resource",
            {
                "kind": "deployment",
                "name": deployment,
                "namespace": namespace,
                "patch": [{"op": "replace", "path": "/spec/template/spec/containers/0/resources/limits/memory", "value": memory_limit}],
                "patch_type": "json"
            }
        )


class CircuitBreaker:
    """Simple circuit breaker to prevent repeated failures."""

    def __init__(self, failure_threshold: int = 5, success_threshold: int = 2, timeout: int = 300):
        """Initialize circuit breaker.
        
        Args:
            failure_threshold: Number of failures before opening
            success_threshold: Number of successes needed to close
            timeout: Seconds before attempting to close after opening
        """
        self.failure_threshold = failure_threshold
        self.success_threshold = success_threshold
        self.timeout = timeout

        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open

    def reset(self):
        """Reset the circuit breaker to closed state."""
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None
        self.state = "closed"

    def is_open(self) -> bool:
        """Check if circuit breaker is open."""
        if self.state == "closed":
            return False

        if self.state == "open":
            # Check if we should move to half-open
            if self.last_failure_time:
                elapsed = (datetime.utcnow() - self.last_failure_time).total_seconds()
                if elapsed >= self.timeout:
                    self.state = "half-open"
                    return False
            return True

        return False  # half-open allows attempts

    def record_success(self):
        """Record a successful execution."""
        if self.state == "half-open":
            self.success_count += 1
            if self.success_count >= self.success_threshold:
                self.state = "closed"
                self.failure_count = 0
                self.success_count = 0
        elif self.state == "closed":
            self.failure_count = max(0, self.failure_count - 1)

    def record_failure(self):
        """Record a failed execution."""
        self.failure_count += 1
        self.last_failure_time = datetime.utcnow()

        if self.failure_count >= self.failure_threshold:
            self.state = "open"
            self.success_count = 0
